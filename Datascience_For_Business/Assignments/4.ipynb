{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSFB Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will begin to work with text data and natural language processing. You will analyze aspects of th DonorsChoose.org program. Aspects of this project were first posed as a Kaggle challenge and the data comes from [Kaggle DonorsChoose.org Application Screening challenge](https://www.kaggle.com/c/donorschoose-application-screening/data). We have changed the nature of what you need to do in this assignment (so it does not track what was done in the Kaggle Challenge), but nevertheless using or referring to the Kaggle Challenge repository is not allowed for the assignment.\n",
    "\n",
    "###  DonorsChoose.org  \n",
    "  \n",
    "Founded in 2000 by a high school teacher in the Bronx, DonorsChoose.org empowers public school teachers from across the country to request much-needed materials and experiences for their students. At any given time, there are thousands of classroom requests that can be brought to life with a gift of any amount. DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website. In this assignment, you will analyze the text of the essays and requirements from each proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cached.imagescaler.hbpl.co.uk/resize/scaleWidth/580/cached.offlinehbpl.hbpl.co.uk/news/NST/C8B9CC1D-03B0-9B80-4CFE78B5B539240F.jpg\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "Image source: https://cached.imagescaler.hbpl.co.uk/resize/scaleWidth/580/cached.offlinehbpl.hbpl.co.uk/news/NST/C8B9CC1D-03B0-9B80-4CFE78B5B539240F.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, this dataset includes many different kinds of features with structured and unstructured data. The dataset consists of application materials (see *application_data.csv*) and resources requested (see *resource_data.csv*). The application materials (see *application_data.csv*) contain the following features.\n",
    "\n",
    "| Feature name  | Description  |\n",
    "|----------------|--------------|\n",
    "| id  | Unique id of the project application    |\n",
    "| teacher_id    | id of the teacher submitting the application  |\n",
    "| teacher_prefix    | title of the teacher's name (Ms., Mr., etc.)    |\n",
    "| school_state    | US state of the teacher's school    |\n",
    "| project_submitted_datetime    | application submission timestamp    |\n",
    "| project_grade_category    | school grade levels (PreK-2, 3-5, 6-8, and 9-12)   |\n",
    "| project_subject_categories   | category of the project (e.g., \"Music & The Arts\")    |\n",
    "| project_subject_subcategories    | sub-category of the project (e.g., \"Visual Arts\")    |\n",
    "| project_title    | title of the project    |\n",
    "| project_essay_1    | first essay*   |\n",
    "| project_essay_2    | second essay*    |\n",
    "| project_essay_3    | third essay*   |\n",
    "| project_essay_4    | fourth essay*  |\n",
    "| project_resource_summary    | summary of the resources needed for the project    |\n",
    "| teacher_number_of_previously_posted_projects   | number of previously posted applications by the submitting teacher    |\n",
    "| project_is_approved    | whether DonorsChoose proposal was accepted (0=\"rejected\", 1=\"accepted\"); train.csv only    |\n",
    "\n",
    "\n",
    "\\*Note: Prior to May 17, 2016, the prompts for the essays were as follows:\n",
    "\n",
    "  * project_essay_1: \"Introduce us to your classroom\"  \n",
    "\n",
    "  * project_essay_2: \"Tell us more about your students\"  \n",
    "\n",
    "  * project_essay_3: \"Describe how your students will use the materials you're requesting\"  \n",
    "\n",
    "  * project_essay_4: \"Close by sharing why your project will make a difference\"  \n",
    "\n",
    "Starting on May 17, 2016, the number of essays was reduced from 4 to 2, and the prompts for the first 2 essays were changed to the following:\n",
    "\n",
    "  * project_essay_1: \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"  \n",
    "\n",
    "  * project_essay_2: \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"  \n",
    "\n",
    "For all projects with project_submitted_datetime of 2016-05-17 and later, the values of project_essay_3 and project_essay_4 will be missing (i.e. NaN).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special NLP Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use several new libraries for this assignment - so be sure to first install those on your machine by with `pip` in a terminal:\n",
    "\n",
    "    pip install --user -U nltk\n",
    "    pip install -U gensim\n",
    "    pip install -U spacy\n",
    "    pip install -U pyldavis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import math  \n",
    "import copy\n",
    "\n",
    "from pprint import pprint  # nicer printing\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Other NLP\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# General Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Special Plotting\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "\n",
    "# ignore some warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the maximum number of rows displayed by pandas\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "# Set some CONSTANTS that will be used later\n",
    "SEED    = 41  # base to generate a random number\n",
    "SCORE   = 'roc_auc'\n",
    "FIGSIZE = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: To use a particular model in the `spacy` package, you need to manually download and install that particular model. You will need to run the following code from a terminal: `python -m spacy download en_core_web_sm`. Rather than doing that manually from bash in a separate terminal program, do it inline below using a \"magic\" command in jupyter. HINT: Use *!* followed by a bash command in a cell to run a bash command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /Users/philippspiess/anaconda3/lib/python3.6/site-packages (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Download en_core_web_sm for spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: To confirm that `spacy` is working (and `en_core_web_sm` is installed on your computer), you should be able to use `spacy.load()` to build a `Language` object to perform some basic nlp. Do that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x108d7cc88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test use of spacy by using the spacy.load() function\n",
    "spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Use nltk.download() to download a list of raw stopwords. (see NLTK documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/philippspiess/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Use the `stopwords` object from `nltk` to build a list of English stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get English Stopwords from NLTK\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Extend your `stop_words` list with some additional stopwords that you believe should be ignored in this particular context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the stop word list \n",
    "setAdditions = {\"students\", \"class\",'classroom','edu'} \n",
    "#These could also be included: 'school', 'learning', 'book','study', 'learn','read','many'\n",
    "stop_words = set(list(stop_words) + list(setAdditions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other projects, this project includes a training set too big for GitHub. Through the terminal lab of Jupyter lab, download the data using the *wget* command, unzip it using the *zip* command and check that it's in the root directory of the project. \n",
    "\n",
    "Locations : \n",
    "\n",
    "    Applications dataset: https://storage.googleapis.com/dsfm/application/application_data.csv.zip\n",
    "    Resources dataset: https://storage.googleapis.com/dsfm/application/resource_data.csv.zip\n",
    "    \n",
    "Hint: Use *wget* and *unzip* commands. Use *!* followed by a bash command in a cell to run a bash command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: wget the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_CH.\n",
      "Warning: Failed to set locale category LC_TIME to en_CH.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_CH.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_CH.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_CH.\n",
      "--2019-11-17 18:54:31--  https://storage.googleapis.com/dsfm/application/application_data.csv.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400a:801::2010, 172.217.168.16\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400a:801::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 113169833 (108M) [application/zip]\n",
      "Saving to: â€˜application_data.csv.zip.2â€™\n",
      "\n",
      "application_data.cs 100%[===================>] 107.93M  4.69MB/s    in 23s     \n",
      "\n",
      "2019-11-17 18:54:54 (4.68 MB/s) - â€˜application_data.csv.zip.2â€™ saved [113169833/113169833]\n",
      "\n",
      "Warning: Failed to set locale category LC_NUMERIC to en_CH.\n",
      "Warning: Failed to set locale category LC_TIME to en_CH.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_CH.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_CH.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_CH.\n",
      "--2019-11-17 18:54:55--  https://storage.googleapis.com/dsfm/application/resource_data.csv.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400a:801::2010, 172.217.168.16\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400a:801::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42396552 (40M) [application/zip]\n",
      "Saving to: â€˜resource_data.csv.zip.1â€™\n",
      "\n",
      "resource_data.csv.z 100%[===================>]  40.43M  4.74MB/s    in 8.4s    \n",
      "\n",
      "2019-11-17 18:55:03 (4.79 MB/s) - â€˜resource_data.csv.zip.1â€™ saved [42396552/42396552]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wget the data\n",
    "!wget https://storage.googleapis.com/dsfm/application/application_data.csv.zip\n",
    "!wget https://storage.googleapis.com/dsfm/application/resource_data.csv.zip \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: unzip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "!unzip application_data.csv.zip\n",
    "!unzip resource_data.csv.zip \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Load `application_data.csv` and investigate it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182080, 16)\n",
      "             id                        teacher_id teacher_prefix school_state  \\\n",
      "177593  p004759  18a806c803fc047c974f2c908e15e7f5           Mrs.           SC   \n",
      "\n",
      "       project_submitted_datetime project_grade_category  \\\n",
      "177593        2016-07-18 09:52:44          Grades PreK-2   \n",
      "\n",
      "       project_subject_categories project_subject_subcategories  \\\n",
      "177593        Literacy & Language                      Literacy   \n",
      "\n",
      "                 project_title  \\\n",
      "177593  Time To Get Organized!   \n",
      "\n",
      "                                          project_essay_1  \\\n",
      "177593  In North Charleston, my school is labeled as \\...   \n",
      "\n",
      "                                          project_essay_2 project_essay_3  \\\n",
      "177593  My students are separated into four literacy g...             NaN   \n",
      "\n",
      "       project_essay_4                           project_resource_summary  \\\n",
      "177593             NaN  My students need help getting organized with a...   \n",
      "\n",
      "        teacher_number_of_previously_posted_projects  project_is_approved  \n",
      "177593                                             2                    1  \n"
     ]
    }
   ],
   "source": [
    "# Load applications\n",
    "application_data = pd.read_csv('application_data.csv')\n",
    "print(application_data.shape)\n",
    "print(application_data.sample(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Load `resource_data.csv` and investigate it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1541272, 4)\n",
      "              id                                        description  quantity  \\\n",
      "994960   p060085  Elmers Washable No-Run School Glue, 4 oz, 1 Bo...         6   \n",
      "1102090  p185543                       If You Give a Mouse a Cookie         1   \n",
      "1436320  p172858  Wausau Paper Astrobrights Colored Paper, 8.5\" ...         1   \n",
      "790297   p016253  Staples 5.5 Quart Plastic Locking Lid Containe...         1   \n",
      "749012   p115521             SKLZ Mini Practice Baseballs - 12 Pack         5   \n",
      "\n",
      "         price  \n",
      "994960    7.95  \n",
      "1102090  12.40  \n",
      "1436320  10.22  \n",
      "790297   23.88  \n",
      "749012    6.99  \n"
     ]
    }
   ],
   "source": [
    "# Load resources\n",
    "resource_data = pd.read_csv('resource_data.csv')\n",
    "print(resource_data.shape)\n",
    "print(resource_data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Some of the essays are NA. Replace NAs with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA values in essay columns with ''\n",
    "application_data=application_data.fillna('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: To simplify matters, combine all essays into just one feature called \"essays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
      "       'project_submitted_datetime', 'project_grade_category',\n",
      "       'project_subject_categories', 'project_subject_subcategories',\n",
      "       'project_title', 'project_resource_summary',\n",
      "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
      "       'essays'],\n",
      "      dtype='object')\n",
      "(182080, 13)\n"
     ]
    }
   ],
   "source": [
    "# Combine essays\n",
    "application_data['essays'] = application_data[['project_essay_1', 'project_essay_2','project_essay_3','project_essay_4']].astype(str).apply(''.join, axis=1)\n",
    "application_data=application_data.drop(['project_essay_1', 'project_essay_2','project_essay_3','project_essay_4'], axis=1)\n",
    "print(application_data.columns)\n",
    "print(application_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Merge the resources and application datasets on the *id* feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
      "       'project_submitted_datetime', 'project_grade_category',\n",
      "       'project_subject_categories', 'project_subject_subcategories',\n",
      "       'project_title', 'project_resource_summary',\n",
      "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
      "       'essays', 'description', 'quantity', 'price'],\n",
      "      dtype='object')\n",
      "(1081830, 16)\n"
     ]
    }
   ],
   "source": [
    "# Merge two datasets\n",
    "data = pd.merge(application_data, resource_data, on='id')\n",
    "\n",
    "# Check the data to confirm it worked\n",
    "print(data.columns)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Keep the following data for additional analysis (the id and the text features): `id`, `school_state`, `project_subject_categories`, `project_subject_subcategories`, `essays`, `description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = ['school_state', 'project_subject_categories', 'project_subject_subcategories', 'essays', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['school_state', 'project_subject_categories',\n",
      "       'project_subject_subcategories', 'essays', 'description', 'id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Keep the Text Features\n",
    "FEATURE_NAMES.append('id')\n",
    "merged = data[FEATURE_NAMES]\n",
    "FEATURE_NAMES.remove('id')\n",
    "print(merged.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Preprocess Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an independent copy of the data so we can restart here when testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['school_state', 'project_subject_categories',\n",
      "       'project_subject_subcategories', 'essays', 'description', 'id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = copy.copy(merged)  # when \"merged\" is the pandas dataframe\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Define a custom function `clean_punctuation()` to remove some punctuation from your text data. You don't have to do absolutely everything one might want to do - just show that you can do it. Start with each some easy operations with `str.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to clean punctuation from given text\n",
    "def clean_punctuation(txt):\n",
    "    txt = str(txt)\n",
    "    txt = txt.replace(\".\", \"\")\n",
    "    txt = txt.replace(\"!\", \"\")\n",
    "    txt = txt.replace(\",\", \"\")\n",
    "    txt = txt.replace(\";\", \"\")\n",
    "    txt = txt.lower()\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Use the `apply()` function from pandas to _apply_ that function down the `essays` column of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy &amp; language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>most of my kindergarten students come from low...</td>\n",
       "      <td>apple - ipod nanoï¿½ 16gb mp3 player (8th genera...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy &amp; language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>most of my kindergarten students come from low...</td>\n",
       "      <td>apple - ipod nanoï¿½ 16gb mp3 player (8th genera...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga</td>\n",
       "      <td>music &amp; the arts health &amp; sports</td>\n",
       "      <td>performing arts team sports</td>\n",
       "      <td>our elementary school is a culturally rich sch...</td>\n",
       "      <td>reebok girls' fashion dance graphic t-shirt - ...</td>\n",
       "      <td>p039565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ut</td>\n",
       "      <td>math &amp; science literacy &amp; language</td>\n",
       "      <td>applied sciences literature &amp; writing</td>\n",
       "      <td>hello\\r\\nmy name is mrs brotherton i teach 5th...</td>\n",
       "      <td>3doodler start full edu bundle</td>\n",
       "      <td>p233823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nc</td>\n",
       "      <td>health &amp; sports</td>\n",
       "      <td>health &amp; wellness</td>\n",
       "      <td>my students are the greatest students but are ...</td>\n",
       "      <td>ball pg 4'' poly set of 6 colors</td>\n",
       "      <td>p185307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state          project_subject_categories  \\\n",
       "0           nv                 literacy & language   \n",
       "1           nv                 literacy & language   \n",
       "2           ga    music & the arts health & sports   \n",
       "3           ut  math & science literacy & language   \n",
       "4           nc                     health & sports   \n",
       "\n",
       "           project_subject_subcategories  \\\n",
       "0                               literacy   \n",
       "1                               literacy   \n",
       "2            performing arts team sports   \n",
       "3  applied sciences literature & writing   \n",
       "4                      health & wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  most of my kindergarten students come from low...   \n",
       "1  most of my kindergarten students come from low...   \n",
       "2  our elementary school is a culturally rich sch...   \n",
       "3  hello\\r\\nmy name is mrs brotherton i teach 5th...   \n",
       "4  my students are the greatest students but are ...   \n",
       "\n",
       "                                         description       id  \n",
       "0  apple - ipod nanoï¿½ 16gb mp3 player (8th genera...  p036502  \n",
       "1  apple - ipod nanoï¿½ 16gb mp3 player (8th genera...  p036502  \n",
       "2  reebok girls' fashion dance graphic t-shirt - ...  p039565  \n",
       "3                     3doodler start full edu bundle  p233823  \n",
       "4                   ball pg 4'' poly set of 6 colors  p185307  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply your function to clean the essays column\n",
    "for feature in FEATURE_NAMES:\n",
    "    data[feature] = data[feature].apply(lambda txt : clean_punctuation(txt)) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Define **another** custom function called `clean_re()` to clean your text data using regular expressions. Do at least two \"cleanings\" (i.e., show that you can use the `re` library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to clean some given text\n",
    "def clean_re(txt):\n",
    "    txt=str(txt)\n",
    "    txt = re.sub(r'[^\\w\\s]','',txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy  language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>most of my kindergarten students come from low...</td>\n",
       "      <td>apple  ipod nano 16gb mp3 player 8th generatio...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy  language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>most of my kindergarten students come from low...</td>\n",
       "      <td>apple  ipod nano 16gb mp3 player 8th generatio...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga</td>\n",
       "      <td>music  the arts health  sports</td>\n",
       "      <td>performing arts team sports</td>\n",
       "      <td>our elementary school is a culturally rich sch...</td>\n",
       "      <td>reebok girls fashion dance graphic tshirt  dd ...</td>\n",
       "      <td>p039565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ut</td>\n",
       "      <td>math  science literacy  language</td>\n",
       "      <td>applied sciences literature  writing</td>\n",
       "      <td>hellornmy name is mrs brotherton i teach 5th g...</td>\n",
       "      <td>3doodler start full edu bundle</td>\n",
       "      <td>p233823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nc</td>\n",
       "      <td>health  sports</td>\n",
       "      <td>health  wellness</td>\n",
       "      <td>my students are the greatest students but are ...</td>\n",
       "      <td>ball pg 4 poly set of 6 colors</td>\n",
       "      <td>p185307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state        project_subject_categories  \\\n",
       "0           nv                literacy  language   \n",
       "1           nv                literacy  language   \n",
       "2           ga    music  the arts health  sports   \n",
       "3           ut  math  science literacy  language   \n",
       "4           nc                    health  sports   \n",
       "\n",
       "          project_subject_subcategories  \\\n",
       "0                              literacy   \n",
       "1                              literacy   \n",
       "2           performing arts team sports   \n",
       "3  applied sciences literature  writing   \n",
       "4                      health  wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  most of my kindergarten students come from low...   \n",
       "1  most of my kindergarten students come from low...   \n",
       "2  our elementary school is a culturally rich sch...   \n",
       "3  hellornmy name is mrs brotherton i teach 5th g...   \n",
       "4  my students are the greatest students but are ...   \n",
       "\n",
       "                                         description       id  \n",
       "0  apple  ipod nano 16gb mp3 player 8th generatio...  p036502  \n",
       "1  apple  ipod nano 16gb mp3 player 8th generatio...  p036502  \n",
       "2  reebok girls fashion dance graphic tshirt  dd ...  p039565  \n",
       "3                     3doodler start full edu bundle  p233823  \n",
       "4                     ball pg 4 poly set of 6 colors  p185307  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply clean_re() to all features\n",
    "for feature in FEATURE_NAMES:\n",
    "    data[feature] = data[feature].apply(lambda txt : clean_re(txt)) \n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Remove stopwords. (Hint: use stopwords from nltk's `stopwords()` plus any additions you'd like to make. Then, again, define a custom function and then apply it to all features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to remove stopwords\n",
    "def remove_stopWords(txt):\n",
    "    words = txt.split(' ')\n",
    "    wordsFiltered = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            wordsFiltered.append(word)\n",
    "    txt = \" \".join(wordsFiltered)\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy  language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>kindergarten come lowincome households conside...</td>\n",
       "      <td>apple  ipod nano 16gb mp3 player 8th generatio...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy  language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>kindergarten come lowincome households conside...</td>\n",
       "      <td>apple  ipod nano 16gb mp3 player 8th generatio...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga</td>\n",
       "      <td>music  arts health  sports</td>\n",
       "      <td>performing arts team sports</td>\n",
       "      <td>elementary school culturally rich school diver...</td>\n",
       "      <td>reebok girls fashion dance graphic tshirt  dd ...</td>\n",
       "      <td>p039565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ut</td>\n",
       "      <td>math  science literacy  language</td>\n",
       "      <td>applied sciences literature  writing</td>\n",
       "      <td>hellornmy name mrs brotherton teach 5th grade ...</td>\n",
       "      <td>3doodler start full bundle</td>\n",
       "      <td>p233823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nc</td>\n",
       "      <td>health  sports</td>\n",
       "      <td>health  wellness</td>\n",
       "      <td>greatest socially economically disadvantaged  ...</td>\n",
       "      <td>ball pg 4 poly set 6 colors</td>\n",
       "      <td>p185307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state        project_subject_categories  \\\n",
       "0           nv                literacy  language   \n",
       "1           nv                literacy  language   \n",
       "2           ga        music  arts health  sports   \n",
       "3           ut  math  science literacy  language   \n",
       "4           nc                    health  sports   \n",
       "\n",
       "          project_subject_subcategories  \\\n",
       "0                              literacy   \n",
       "1                              literacy   \n",
       "2           performing arts team sports   \n",
       "3  applied sciences literature  writing   \n",
       "4                      health  wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  kindergarten come lowincome households conside...   \n",
       "1  kindergarten come lowincome households conside...   \n",
       "2  elementary school culturally rich school diver...   \n",
       "3  hellornmy name mrs brotherton teach 5th grade ...   \n",
       "4  greatest socially economically disadvantaged  ...   \n",
       "\n",
       "                                         description       id  \n",
       "0  apple  ipod nano 16gb mp3 player 8th generatio...  p036502  \n",
       "1  apple  ipod nano 16gb mp3 player 8th generatio...  p036502  \n",
       "2  reebok girls fashion dance graphic tshirt  dd ...  p039565  \n",
       "3                         3doodler start full bundle  p233823  \n",
       "4                        ball pg 4 poly set 6 colors  p185307  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to remove stopwords  \n",
    "for feature in FEATURE_NAMES:\n",
    "    data[feature] = data[feature].apply(lambda txt : remove_stopWords(txt)) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Now use Gensimâ€™s `simple_preprocess()` function to tokenize and clean up your text data. TIP: `simple_preprocess()` returns a list of words, so we want to wrap it with a function that joins the list back together into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to wrap simple_preprocess() from gensim\n",
    "def wrap(txt):\n",
    "    words = simple_preprocess(txt)\n",
    "    txt = \" \".join(words)\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>kindergarten come lowincome households conside...</td>\n",
       "      <td>apple ipod nano gb mp player th generation lat...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nv</td>\n",
       "      <td>literacy language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>kindergarten come lowincome households conside...</td>\n",
       "      <td>apple ipod nano gb mp player th generation lat...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga</td>\n",
       "      <td>music arts health sports</td>\n",
       "      <td>performing arts team sports</td>\n",
       "      <td>elementary school culturally rich school diver...</td>\n",
       "      <td>reebok girls fashion dance graphic tshirt dd d...</td>\n",
       "      <td>p039565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ut</td>\n",
       "      <td>math science literacy language</td>\n",
       "      <td>applied sciences literature writing</td>\n",
       "      <td>hellornmy name mrs brotherton teach th grade a...</td>\n",
       "      <td>doodler start full bundle</td>\n",
       "      <td>p233823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nc</td>\n",
       "      <td>health sports</td>\n",
       "      <td>health wellness</td>\n",
       "      <td>greatest socially economically disadvantaged i...</td>\n",
       "      <td>ball pg poly set colors</td>\n",
       "      <td>p185307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state      project_subject_categories  \\\n",
       "0           nv               literacy language   \n",
       "1           nv               literacy language   \n",
       "2           ga        music arts health sports   \n",
       "3           ut  math science literacy language   \n",
       "4           nc                   health sports   \n",
       "\n",
       "         project_subject_subcategories  \\\n",
       "0                             literacy   \n",
       "1                             literacy   \n",
       "2          performing arts team sports   \n",
       "3  applied sciences literature writing   \n",
       "4                      health wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  kindergarten come lowincome households conside...   \n",
       "1  kindergarten come lowincome households conside...   \n",
       "2  elementary school culturally rich school diver...   \n",
       "3  hellornmy name mrs brotherton teach th grade a...   \n",
       "4  greatest socially economically disadvantaged i...   \n",
       "\n",
       "                                         description       id  \n",
       "0  apple ipod nano gb mp player th generation lat...  p036502  \n",
       "1  apple ipod nano gb mp player th generation lat...  p036502  \n",
       "2  reebok girls fashion dance graphic tshirt dd d...  p039565  \n",
       "3                          doodler start full bundle  p233823  \n",
       "4                            ball pg poly set colors  p185307  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply simple_preprocess() to all features\n",
    "for feature in FEATURE_NAMES:\n",
    "    data[feature] = data[feature].apply(lambda txt : wrap(txt)) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Lemmatize the text. (Hint: Define a custom function and then apply it to all features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/philippspiess/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Write a lemmatization function based on nltk.stem.WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "def Lemmatization(txt):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    txt=str(txt)\n",
    "    words = txt.split(' ')\n",
    "    wordsLemma = []\n",
    "    for word in words:\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        wordsLemma.append(word)\n",
    "    return wordsLemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nv]</td>\n",
       "      <td>[literacy, language]</td>\n",
       "      <td>[literacy]</td>\n",
       "      <td>[kindergarten, come, lowincome, household, con...</td>\n",
       "      <td>[apple, ipod, nano, gb, mp, player, th, genera...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nv]</td>\n",
       "      <td>[literacy, language]</td>\n",
       "      <td>[literacy]</td>\n",
       "      <td>[kindergarten, come, lowincome, household, con...</td>\n",
       "      <td>[apple, ipod, nano, gb, mp, player, th, genera...</td>\n",
       "      <td>p036502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ga]</td>\n",
       "      <td>[music, art, health, sport]</td>\n",
       "      <td>[performing, art, team, sport]</td>\n",
       "      <td>[elementary, school, culturally, rich, school,...</td>\n",
       "      <td>[reebok, girl, fashion, dance, graphic, tshirt...</td>\n",
       "      <td>p039565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ut]</td>\n",
       "      <td>[math, science, literacy, language]</td>\n",
       "      <td>[applied, science, literature, writing]</td>\n",
       "      <td>[hellornmy, name, mr, brotherton, teach, th, g...</td>\n",
       "      <td>[doodler, start, full, bundle]</td>\n",
       "      <td>p233823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nc]</td>\n",
       "      <td>[health, sport]</td>\n",
       "      <td>[health, wellness]</td>\n",
       "      <td>[greatest, socially, economically, disadvantag...</td>\n",
       "      <td>[ball, pg, poly, set, color]</td>\n",
       "      <td>p185307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state           project_subject_categories  \\\n",
       "0         [nv]                 [literacy, language]   \n",
       "1         [nv]                 [literacy, language]   \n",
       "2         [ga]          [music, art, health, sport]   \n",
       "3         [ut]  [math, science, literacy, language]   \n",
       "4         [nc]                      [health, sport]   \n",
       "\n",
       "             project_subject_subcategories  \\\n",
       "0                               [literacy]   \n",
       "1                               [literacy]   \n",
       "2           [performing, art, team, sport]   \n",
       "3  [applied, science, literature, writing]   \n",
       "4                       [health, wellness]   \n",
       "\n",
       "                                              essays  \\\n",
       "0  [kindergarten, come, lowincome, household, con...   \n",
       "1  [kindergarten, come, lowincome, household, con...   \n",
       "2  [elementary, school, culturally, rich, school,...   \n",
       "3  [hellornmy, name, mr, brotherton, teach, th, g...   \n",
       "4  [greatest, socially, economically, disadvantag...   \n",
       "\n",
       "                                         description       id  \n",
       "0  [apple, ipod, nano, gb, mp, player, th, genera...  p036502  \n",
       "1  [apple, ipod, nano, gb, mp, player, th, genera...  p036502  \n",
       "2  [reebok, girl, fashion, dance, graphic, tshirt...  p039565  \n",
       "3                     [doodler, start, full, bundle]  p233823  \n",
       "4                       [ball, pg, poly, set, color]  p185307  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply lemmatize_text() to all features  \n",
    "for feature in FEATURE_NAMES:\n",
    "    data[feature] = data[feature].apply(lambda txt : Lemmatization(txt)) \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: What happened to the data in the pandas dataframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: It was converted from long text into a list of individual words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4:  Make an LDA topic model for the ESSAYS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an LDA topic model for the `essays`. Compute the \"Coherence score.\" Visually inspect the topic model by inspecting the top keywords from each model. Gensim provides functions for all of these tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(188025 unique tokens: ['activity', 'alongside', 'always', 'around', 'atrisk']...)\n",
      "K:  2      coherence:  -0.9029530240468011\n",
      "K:  4      coherence:  -0.9767504846041583\n",
      "K:  10      coherence:  -1.3412588173843978\n",
      "[(0,\n",
      "  '0.021*\"school\" + 0.013*\"learning\" + 0.010*\"need\" + 0.010*\"help\" + '\n",
      "  '0.009*\"learn\" + 0.007*\"many\" + 0.007*\"work\" + 0.007*\"use\" + '\n",
      "  '0.006*\"material\" + 0.006*\"skill\"'),\n",
      " (1,\n",
      "  '0.042*\"book\" + 0.031*\"reading\" + 0.018*\"read\" + 0.016*\"school\" + '\n",
      "  '0.012*\"love\" + 0.010*\"help\" + 0.010*\"library\" + 0.009*\"need\" + 0.009*\"many\" '\n",
      "  '+ 0.008*\"learn\"')]\n",
      "Best K:  2       Best coherence Score:  -0.9029530240468011\n"
     ]
    }
   ],
   "source": [
    "data_essays = data['essays'].tolist()\n",
    "\n",
    "id2word = corpora.Dictionary(data_essays)\n",
    "texts = data_essays\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(id2word)\n",
    "\n",
    "k = [2,4,10]\n",
    "best_K =2\n",
    "best_coherence=-100\n",
    "for K in k:\n",
    "    model = gensim.models.ldamodel.LdaModel(corpus, K, id2word)\n",
    "    cm = CoherenceModel(model=model, corpus=corpus, coherence='u_mass')\n",
    "    coherence = cm.get_coherence()  # get coherence value\n",
    "    print('K: ', K, '     coherence: ', coherence)\n",
    "    if coherence>best_coherence:\n",
    "        best_K = K\n",
    "        best_coherence = coherence\n",
    "        lda_model = model\n",
    "        \n",
    "pprint(lda_model.print_topics())\n",
    "print('Best K: ', best_K, '      Best coherence Score: ', best_coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use gensim and the following three variables, then you can visualize topics & keywords with the code below.\n",
    "\n",
    "    lda_model:    this is an LDA model generated by gensim.models.ldamodel.LdaModel()\n",
    "    id2word:      this is the dictionary term IDs from corpora.Dictionary()\n",
    "    corpus:       this is the collection of \"documents\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el76501137713608089511690326\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el76501137713608089511690326_data = {\"mdsDat\": {\"x\": [0.08684034645557404, -0.08684034645557404], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [69.57942962646484, 30.420568466186523]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [1777422.0, 1327012.0, 750621.0, 412070.0, 905959.0, 296472.0, 448229.0, 174189.0, 164575.0, 600206.0, 190277.0, 139797.0, 430079.0, 694800.0, 418580.0, 432621.0, 202609.0, 291008.0, 1053995.0, 405278.0, 691398.0, 378557.0, 344581.0, 106843.0, 99536.0, 864975.0, 316157.0, 1406810.0, 92951.0, 2680278.0, 418579.71875, 378556.65625, 430078.78125, 316156.5625, 254617.03125, 344580.65625, 262133.171875, 174634.640625, 142131.625, 130631.125, 142052.53125, 118681.96875, 117253.828125, 105260.2890625, 93035.828125, 108021.3203125, 107809.828125, 95439.765625, 101860.3984375, 83518.984375, 85237.9375, 70329.28125, 152309.28125, 66404.3046875, 59966.453125, 59951.5, 57631.6875, 55059.5390625, 62627.20703125, 55254.69140625, 432254.0625, 134229.4375, 161244.984375, 80331.734375, 71600.796875, 69437.6640625, 201336.375, 626703.375, 639821.0625, 232927.4375, 353945.71875, 1288022.625, 607138.0625, 1993744.75, 521925.25, 667481.3125, 284042.5625, 989065.0625, 895453.5, 982223.875, 538734.9375, 379843.71875, 231785.796875, 389989.875, 475990.28125, 681427.5625, 390469.9375, 574397.375, 521225.625, 473331.25, 558430.1875, 460921.1875, 408773.375, 415300.3125, 410008.15625, 400874.84375, 397223.53125, 1777421.75, 1327011.625, 750621.125, 412069.90625, 296472.0, 174189.140625, 164574.46875, 92951.0703125, 139796.625, 99535.640625, 72059.6484375, 77507.625, 49779.37890625, 54972.28125, 50461.7421875, 59218.12109375, 38638.90625, 88213.1015625, 38338.609375, 30690.880859375, 26872.48828125, 24664.978515625, 22106.24609375, 22399.96484375, 39394.55859375, 21433.744140625, 15390.5517578125, 22470.544921875, 14458.3603515625, 13221.982421875, 52204.23046875, 25444.603515625, 105043.015625, 76173.59375, 162532.09375, 87616.2421875, 73621.265625, 155962.21875, 88723.71875, 309162.84375, 508736.375, 179331.328125, 68630.15625, 292543.65625, 117568.3828125, 209565.25, 293925.8125, 686533.5, 372568.0, 281390.59375, 424587.03125, 306545.53125, 388936.25, 339493.375, 277366.4375, 198509.25, 237256.390625, 213807.296875, 325957.875, 211404.875, 208083.734375, 184676.390625, 176388.03125, 171782.15625, 172270.125], \"Term\": [\"book\", \"reading\", \"read\", \"library\", \"love\", \"reader\", \"level\", \"text\", \"seating\", \"grade\", \"story\", \"chair\", \"math\", \"want\", \"supply\", \"activity\", \"interest\", \"english\", \"many\", \"language\", \"new\", \"art\", \"science\", \"sit\", \"literature\", \"year\", \"technology\", \"help\", \"novel\", \"school\", \"supply\", \"art\", \"math\", \"technology\", \"play\", \"science\", \"game\", \"item\", \"paper\", \"healthy\", \"handson\", \"pencil\", \"music\", \"equipment\", \"stem\", \"computer\", \"food\", \"physical\", \"team\", \"board\", \"snack\", \"sensory\", \"basic\", \"marker\", \"design\", \"engineering\", \"kit\", \"motor\", \"recess\", \"lab\", \"activity\", \"concept\", \"problem\", \"creativity\", \"interactive\", \"color\", \"tool\", \"material\", \"use\", \"using\", \"create\", \"learning\", \"skill\", \"school\", \"project\", \"work\", \"education\", \"need\", \"learn\", \"help\", \"make\", \"experience\", \"used\", \"way\", \"also\", \"many\", \"opportunity\", \"come\", \"day\", \"able\", \"year\", \"child\", \"would\", \"time\", \"new\", \"want\", \"love\", \"book\", \"reading\", \"read\", \"library\", \"reader\", \"text\", \"seating\", \"novel\", \"chair\", \"literature\", \"nonfiction\", \"flexible\", \"fiction\", \"author\", \"stool\", \"series\", \"genre\", \"comprehension\", \"wobble\", \"leveled\", \"aloud\", \"chapter\", \"biography\", \"reluctant\", \"wiggle\", \"cushion\", \"seuss\", \"selection\", \"hokki\", \"alouds\", \"graphic\", \"magazine\", \"sit\", \"spanish\", \"story\", \"comfortable\", \"character\", \"interest\", \"option\", \"level\", \"love\", \"english\", \"desk\", \"grade\", \"literacy\", \"language\", \"want\", \"school\", \"many\", \"new\", \"help\", \"year\", \"need\", \"learn\", \"come\", \"home\", \"day\", \"time\", \"learning\", \"child\", \"able\", \"also\", \"one\", \"make\", \"work\"], \"Total\": [1777422.0, 1327012.0, 750621.0, 412070.0, 905959.0, 296472.0, 448229.0, 174189.0, 164575.0, 600206.0, 190277.0, 139797.0, 430079.0, 694800.0, 418580.0, 432621.0, 202609.0, 291008.0, 1053995.0, 405278.0, 691398.0, 378557.0, 344581.0, 106843.0, 99536.0, 864975.0, 316157.0, 1406810.0, 92951.0, 2680278.0, 418580.4375, 378557.34375, 430079.5625, 316157.25, 254617.671875, 344581.59375, 262133.890625, 174635.3125, 142132.21875, 130631.7421875, 142053.21875, 118682.5546875, 117254.4140625, 105260.8125, 93036.390625, 108022.015625, 107810.5546875, 95440.421875, 101861.1328125, 83519.671875, 85238.6484375, 70329.875, 152310.609375, 66404.8828125, 59966.99609375, 59952.0625, 57632.25, 55060.0859375, 62627.85546875, 55255.28515625, 432621.09375, 134242.25, 161593.921875, 80338.015625, 71602.5625, 69438.859375, 204276.5, 684664.3125, 705125.375, 246230.265625, 392268.90625, 1613980.5, 719146.75, 2680278.25, 631840.125, 839751.4375, 322141.96875, 1378001.25, 1234946.875, 1406810.875, 710517.125, 469889.375, 261653.5, 509492.125, 660666.6875, 1053995.5, 514974.96875, 851763.8125, 758482.0, 681415.0, 864975.75, 672326.0625, 563890.3125, 629107.625, 691398.75, 694800.625, 905959.875, 1777422.375, 1327012.625, 750621.75, 412070.53125, 296472.59375, 174189.796875, 164575.09375, 92951.6484375, 139797.515625, 99536.4296875, 72060.2265625, 77508.328125, 49779.93359375, 54972.90625, 50462.39453125, 59218.9609375, 38639.50390625, 88214.515625, 38339.26953125, 30691.45703125, 26873.109375, 24665.640625, 22106.87890625, 22400.646484375, 39395.89453125, 21434.55078125, 15391.1484375, 22471.427734375, 14458.9912109375, 13222.5849609375, 52375.8359375, 25453.3046875, 106843.265625, 82421.8203125, 190277.984375, 104098.2734375, 85475.75, 202609.9375, 106341.8125, 448229.25, 905959.875, 291008.09375, 82728.6640625, 600206.875, 176349.1875, 405278.8125, 694800.625, 2680278.25, 1053995.5, 691398.75, 1406810.875, 864975.75, 1378001.25, 1234946.875, 851763.8125, 482139.28125, 758482.0, 629107.625, 1613980.5, 672326.0625, 681415.0, 660666.6875, 524770.125, 710517.125, 839751.4375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3626999855041504, 0.3619000017642975, 0.3625999987125397, 0.3605000078678131, 0.3625999987125397, 0.3626999855041504, 0.3626999855041504, 0.3481999933719635, 0.2741999924182892, 0.265500009059906, 0.30720001459121704, 0.2599000036716461, 0.1370999962091446, 0.19339999556541443, 0.06679999828338623, 0.17159999907016754, 0.1331000030040741, 0.23680000007152557, 0.031099999323487282, 0.041200000792741776, 0.0034000000450760126, 0.08590000122785568, 0.15000000596046448, 0.24150000512599945, 0.09539999812841415, 0.03480000048875809, -0.07349999994039536, 0.08590000122785568, -0.031300000846385956, -0.012400000356137753, -0.0017000000225380063, -0.07490000128746033, -0.014800000004470348, 0.04100000113248825, -0.05260000005364418, -0.1597999930381775, -0.18729999661445618, -0.4618000090122223, 1.1900999546051025, 1.1900999546051025, 1.1900999546051025, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.190000057220459, 1.1868000030517578, 1.1897000074386597, 1.1730999946594238, 1.111199975013733, 1.0324000120162964, 1.017699956893921, 1.0407999753952026, 0.9283999800682068, 1.0089000463485718, 0.8185999989509583, 0.6129999756813049, 0.7059000134468079, 1.0032000541687012, 0.4713999927043915, 0.784600019454956, 0.5304999947547913, 0.329800009727478, -0.1720000058412552, 0.1500999927520752, 0.29109999537467957, -0.007899999618530273, 0.1527000069618225, -0.07490000128746033, -0.10130000114440918, 0.06809999793767929, 0.302700012922287, 0.027899999171495438, 0.11079999804496765, -0.40959998965263367, 0.03310000151395798, 0.003800000064074993, -0.08460000157356262, 0.0997999981045723, -0.2296999990940094, -0.39399999380111694], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.440199851989746, -5.5406999588012695, -5.413099765777588, -5.720799922943115, -5.937300205230713, -5.634699821472168, -5.908199787139893, -6.3144001960754395, -6.520299911499023, -6.604700088500977, -6.520899772644043, -6.7006001472473145, -6.712699890136719, -6.8206000328063965, -6.9440999031066895, -6.7947001457214355, -6.7967000007629395, -6.918600082397461, -6.853499889373779, -7.052000045776367, -7.031599998474121, -7.223899841308594, -6.451200008392334, -7.281300067901611, -7.383299827575684, -7.383500099182129, -7.422999858856201, -7.468699932098389, -7.339900016784668, -7.465099811553955, -5.408100128173828, -6.577499866485596, -6.394100189208984, -7.09089994430542, -7.205999851226807, -7.236599922180176, -6.172100067138672, -5.036600112915039, -5.015900135040283, -6.026299953460693, -5.607900142669678, -4.316199779510498, -5.068299770355225, -3.879300117492676, -5.2195000648498535, -4.973599910736084, -5.827899932861328, -4.5802998542785645, -4.679699897766113, -4.587200164794922, -5.18779993057251, -5.537300109863281, -6.031300067901611, -5.510900020599365, -5.311699867248535, -4.952899932861328, -5.509699821472168, -5.123700141906738, -5.220900058746338, -5.317299842834473, -5.151899814605713, -5.343800067901611, -5.463900089263916, -5.4481000900268555, -5.460899829864502, -5.483399868011475, -5.492599964141846, -3.166800022125244, -3.4590001106262207, -4.028800010681152, -4.628499984741211, -4.957799911499023, -5.48960018157959, -5.54640007019043, -6.117599964141846, -5.709499835968018, -6.049200057983398, -6.372200012207031, -6.299300193786621, -6.742099761962891, -6.642899990081787, -6.728499889373779, -6.56850004196167, -6.995500087738037, -6.170000076293945, -7.003300189971924, -7.225800037384033, -7.35860013961792, -7.444300174713135, -7.553899765014648, -7.5406999588012695, -6.976099967956543, -7.584799766540527, -7.915999889373779, -7.537499904632568, -7.978400230407715, -8.06779956817627, -6.6946001052856445, -7.4131999015808105, -5.995299816131592, -6.316699981689453, -5.558800220489502, -6.176799774169922, -6.350800037384033, -5.600100040435791, -6.1641998291015625, -4.915800094604492, -4.417799949645996, -5.4604997634887695, -6.421000003814697, -4.971099853515625, -5.882699966430664, -5.304699897766113, -4.966400146484375, -4.118100166320801, -4.729300022125244, -5.010000228881836, -4.598599910736084, -4.9243998527526855, -4.686299800872803, -4.822299957275391, -5.024400234222412, -5.35890007019043, -5.180600166320801, -5.284599781036377, -4.86299991607666, -5.295899868011475, -5.311800003051758, -5.431099891662598, -5.4770002365112305, -5.503499984741211, -5.500699996948242]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.6946295499801636, 0.3053704500198364, 0.9991514682769775, 0.0008483174024149776, 3.721192115335725e-05, 0.9999586939811707, 7.562818063888699e-05, 0.9999557733535767, 0.7204691767692566, 0.27952975034713745, 0.9999991059303284, 2.641607807163382e-06, 1.819077988329809e-05, 0.9999834895133972, 0.9999894499778748, 6.565530838997802e-06, 4.523478855844587e-05, 0.9999602437019348, 0.9999919533729553, 1.1973226719419472e-05, 5.626124561786128e-07, 0.9999997615814209, 7.153203114285134e-06, 0.9999963045120239, 4.05422251787968e-05, 0.9999740123748779, 0.13868260383605957, 0.8613086342811584, 0.6855617165565491, 0.31443819403648376, 0.9999876022338867, 1.4401158296095673e-05, 0.6743618249893188, 0.32563722133636475, 0.15833115577697754, 0.8416662216186523, 1.1336002899042796e-05, 0.9999828338623047, 0.9999905824661255, 9.257371857529506e-06, 0.999901294708252, 9.683985263109207e-05, 0.9023045301437378, 0.0976957380771637, 0.9999251365661621, 7.468444528058171e-05, 4.665364758693613e-05, 0.9999743103981018, 0.6871962547302246, 0.3128037452697754, 0.9999833703041077, 1.6675840015523136e-05, 0.17042461037635803, 0.8295794725418091, 0.8817323446273804, 0.1182677298784256, 0.9999989867210388, 1.667999276833143e-05, 0.383759081363678, 0.6162406206130981, 0.9999922513961792, 9.500211490376387e-06, 0.808368980884552, 0.19163234531879425, 2.0088415112695657e-05, 0.9999812245368958, 1.2901838999823667e-05, 0.999995768070221, 0.9999948740005493, 9.275529919250403e-06, 0.9999966025352478, 3.814844603766687e-06, 2.5880250177579e-05, 0.9999869465827942, 0.5125949382781982, 0.48740527033805847, 0.0032839570194482803, 0.9967191815376282, 0.9999984502792358, 7.039615411486011e-06, 0.9999943375587463, 7.655106855963822e-06, 0.6981919407844543, 0.3018081486225128, 6.916112033650279e-05, 0.9999314546585083, 0.5882740020751953, 0.4117254316806793, 0.9999781847000122, 2.7931961085414514e-05, 0.2302355021238327, 0.76976478099823, 0.9999982118606567, 5.726218660129234e-06, 0.9999956488609314, 1.7351396309095435e-05, 0.9999948143959045, 1.8097816791851074e-05, 0.48291200399398804, 0.5170884728431702, 0.7250951528549194, 0.27490493655204773, 0.7980412244796753, 0.20195907354354858, 0.3102564215660095, 0.6897430419921875, 3.258235665271059e-05, 0.9999850988388062, 2.42676901507366e-06, 0.9999986886978149, 0.33332163095474243, 0.6666772961616516, 1.004657315206714e-05, 0.9999957084655762, 0.4384565055370331, 0.5615436434745789, 0.0003535886644385755, 0.9996737241744995, 0.7582294344902039, 0.24177038669586182, 0.646518886089325, 0.35348159074783325, 0.9999867081642151, 1.5059133147588e-05, 0.9153434634208679, 0.08465608209371567, 0.9999986886978149, 2.3251511720445706e-06, 0.9999984502792358, 1.8161976186092943e-05, 0.9999964833259583, 8.528463695256505e-06, 0.7177533507347107, 0.282246470451355, 0.5930123329162598, 0.4069879949092865, 1.387728116242215e-05, 0.9999968409538269, 1.0758281860034913e-05, 0.9999930262565613, 0.6638754606246948, 0.33612433075904846, 0.7582310438156128, 0.24176903069019318, 0.16567331552505493, 0.8343284726142883, 0.9999984502792358, 7.035702310531633e-06, 0.9999953508377075, 8.425838132097851e-06, 0.9999955892562866, 1.0477740943315439e-05, 0.9999973773956299, 3.927457328245509e-06, 0.9978407621383667, 0.002159734722226858, 0.8260396718978882, 0.1739601492881775, 1.3322288623385248e-06, 0.9999989867210388, 3.3729929782566614e-06, 0.9999979734420776, 7.535723511864489e-07, 0.9999995231628418, 0.9999863505363464, 1.596733636688441e-05, 4.4641568820225075e-05, 0.9999711513519287, 0.7438574433326721, 0.256142795085907, 0.9999982714653015, 2.902070264099166e-06, 6.076253612263827e-06, 0.9999933838844299, 4.4500953663373366e-05, 0.9999809861183167, 0.9999875426292419, 1.4218708201951813e-05, 1.6886482626432553e-05, 0.9999837875366211, 6.49724097456783e-05, 0.9999903440475464, 0.01684710755944252, 0.9831504225730896, 0.8442476987838745, 0.15575262904167175, 0.9999923706054688, 1.1731767699529883e-05, 0.0758051723241806, 0.9241970181465149, 0.9999958276748657, 1.074848205462331e-05, 1.9816736312350258e-05, 0.9999921917915344, 0.14581823348999023, 0.8541818261146545, 0.999998927116394, 2.3890270313131623e-06, 0.999988853931427, 9.81728680926608e-06, 0.9999992251396179, 3.1629829209123272e-06, 5.740864253311884e-06, 0.9999954104423523, 0.6601414084434509, 0.3398575782775879, 0.9856052994728088, 0.014392257668077946, 0.9073861241340637, 0.09261331707239151, 0.8858509659767151, 0.11415096372365952, 0.9459722638130188, 0.054026663303375244, 0.5769640803337097, 0.42303645610809326, 0.7654485106468201, 0.23455122113227844, 2.5383355023222975e-05, 0.9999772906303406, 2.608291651995387e-05, 0.9999929666519165, 0.7948554158210754, 0.2051440328359604, 0.7249158024787903, 0.27508363127708435, 0.6456019282341003, 0.35439836978912354], \"Term\": [\"able\", \"able\", \"activity\", \"activity\", \"aloud\", \"aloud\", \"alouds\", \"alouds\", \"also\", \"also\", \"art\", \"art\", \"author\", \"author\", \"basic\", \"basic\", \"biography\", \"biography\", \"board\", \"board\", \"book\", \"book\", \"chair\", \"chair\", \"chapter\", \"chapter\", \"character\", \"character\", \"child\", \"child\", \"color\", \"color\", \"come\", \"come\", \"comfortable\", \"comfortable\", \"comprehension\", \"comprehension\", \"computer\", \"computer\", \"concept\", \"concept\", \"create\", \"create\", \"creativity\", \"creativity\", \"cushion\", \"cushion\", \"day\", \"day\", \"design\", \"design\", \"desk\", \"desk\", \"education\", \"education\", \"engineering\", \"engineering\", \"english\", \"english\", \"equipment\", \"equipment\", \"experience\", \"experience\", \"fiction\", \"fiction\", \"flexible\", \"flexible\", \"food\", \"food\", \"game\", \"game\", \"genre\", \"genre\", \"grade\", \"grade\", \"graphic\", \"graphic\", \"handson\", \"handson\", \"healthy\", \"healthy\", \"help\", \"help\", \"hokki\", \"hokki\", \"home\", \"home\", \"interactive\", \"interactive\", \"interest\", \"interest\", \"item\", \"item\", \"kit\", \"kit\", \"lab\", \"lab\", \"language\", \"language\", \"learn\", \"learn\", \"learning\", \"learning\", \"level\", \"level\", \"leveled\", \"leveled\", \"library\", \"library\", \"literacy\", \"literacy\", \"literature\", \"literature\", \"love\", \"love\", \"magazine\", \"magazine\", \"make\", \"make\", \"many\", \"many\", \"marker\", \"marker\", \"material\", \"material\", \"math\", \"math\", \"motor\", \"motor\", \"music\", \"music\", \"need\", \"need\", \"new\", \"new\", \"nonfiction\", \"nonfiction\", \"novel\", \"novel\", \"one\", \"one\", \"opportunity\", \"opportunity\", \"option\", \"option\", \"paper\", \"paper\", \"pencil\", \"pencil\", \"physical\", \"physical\", \"play\", \"play\", \"problem\", \"problem\", \"project\", \"project\", \"read\", \"read\", \"reader\", \"reader\", \"reading\", \"reading\", \"recess\", \"recess\", \"reluctant\", \"reluctant\", \"school\", \"school\", \"science\", \"science\", \"seating\", \"seating\", \"selection\", \"selection\", \"sensory\", \"sensory\", \"series\", \"series\", \"seuss\", \"seuss\", \"sit\", \"sit\", \"skill\", \"skill\", \"snack\", \"snack\", \"spanish\", \"spanish\", \"stem\", \"stem\", \"stool\", \"stool\", \"story\", \"story\", \"supply\", \"supply\", \"team\", \"team\", \"technology\", \"technology\", \"text\", \"text\", \"time\", \"time\", \"tool\", \"tool\", \"use\", \"use\", \"used\", \"used\", \"using\", \"using\", \"want\", \"want\", \"way\", \"way\", \"wiggle\", \"wiggle\", \"wobble\", \"wobble\", \"work\", \"work\", \"would\", \"would\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el76501137713608089511690326\", ldavis_el76501137713608089511690326_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el76501137713608089511690326\", ldavis_el76501137713608089511690326_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el76501137713608089511690326\", ldavis_el76501137713608089511690326_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=             x    y  topics  cluster       Freq\n",
       "topic                                          \n",
       "0      0.08684  0.0       1        1  69.579430\n",
       "1     -0.08684  0.0       2        1  30.420568, topic_info=     Category          Freq           Term         Total  loglift  logprob\n",
       "562   Default  1.777422e+06           book  1.777422e+06  30.0000  30.0000\n",
       "68    Default  1.327012e+06        reading  1.327012e+06  29.0000  29.0000\n",
       "459   Default  7.506210e+05           read  7.506210e+05  28.0000  28.0000\n",
       "673   Default  4.120700e+05        library  4.120700e+05  27.0000  27.0000\n",
       "339   Default  9.059590e+05           love  9.059590e+05  26.0000  26.0000\n",
       "67    Default  2.964720e+05         reader  2.964720e+05  25.0000  25.0000\n",
       "212   Default  4.482290e+05          level  4.482290e+05  24.0000  24.0000\n",
       "1381  Default  1.741890e+05           text  1.741890e+05  23.0000  23.0000\n",
       "465   Default  1.645750e+05        seating  1.645750e+05  22.0000  22.0000\n",
       "207   Default  6.002060e+05          grade  6.002060e+05  21.0000  21.0000\n",
       "1029  Default  1.902770e+05          story  1.902770e+05  20.0000  20.0000\n",
       "521   Default  1.397970e+05          chair  1.397970e+05  19.0000  19.0000\n",
       "385   Default  4.300790e+05           math  4.300790e+05  18.0000  18.0000\n",
       "95    Default  6.948000e+05           want  6.948000e+05  17.0000  17.0000\n",
       "730   Default  4.185800e+05         supply  4.185800e+05  16.0000  16.0000\n",
       "0     Default  4.326210e+05       activity  4.326210e+05  15.0000  15.0000\n",
       "210   Default  2.026090e+05       interest  2.026090e+05  14.0000  14.0000\n",
       "19    Default  2.910080e+05        english  2.910080e+05  13.0000  13.0000\n",
       "53    Default  1.053995e+06           many  1.053995e+06  12.0000  12.0000\n",
       "46    Default  4.052780e+05       language  4.052780e+05  11.0000  11.0000\n",
       "58    Default  6.913980e+05            new  6.913980e+05  10.0000  10.0000\n",
       "1403  Default  3.785570e+05            art  3.785570e+05   9.0000   9.0000\n",
       "228   Default  3.445810e+05        science  3.445810e+05   8.0000   8.0000\n",
       "547   Default  1.068430e+05            sit  1.068430e+05   7.0000   7.0000\n",
       "3011  Default  9.953600e+04     literature  9.953600e+04   6.0000   6.0000\n",
       "101   Default  8.649750e+05           year  8.649750e+05   5.0000   5.0000\n",
       "233   Default  3.161570e+05     technology  3.161570e+05   4.0000   4.0000\n",
       "35    Default  1.406810e+06           help  1.406810e+06   3.0000   3.0000\n",
       "679   Default  9.295100e+04          novel  9.295100e+04   2.0000   2.0000\n",
       "74    Default  2.680278e+06         school  2.680278e+06   1.0000   1.0000\n",
       "730    Topic1  4.185797e+05         supply  4.185804e+05   0.3627  -5.4402\n",
       "1403   Topic1  3.785567e+05            art  3.785573e+05   0.3627  -5.5407\n",
       "385    Topic1  4.300788e+05           math  4.300796e+05   0.3627  -5.4131\n",
       "233    Topic1  3.161566e+05     technology  3.161572e+05   0.3627  -5.7208\n",
       "456    Topic1  2.546170e+05           play  2.546177e+05   0.3627  -5.9373\n",
       "228    Topic1  3.445807e+05        science  3.445816e+05   0.3627  -5.6347\n",
       "638    Topic1  2.621332e+05           game  2.621339e+05   0.3627  -5.9082\n",
       "940    Topic1  1.746346e+05           item  1.746353e+05   0.3627  -6.3144\n",
       "1219   Topic1  1.421316e+05          paper  1.421322e+05   0.3627  -6.5203\n",
       "334    Topic1  1.306311e+05        healthy  1.306317e+05   0.3627  -6.6047\n",
       "984    Topic1  1.420525e+05        handson  1.420532e+05   0.3627  -6.5209\n",
       "727    Topic1  1.186820e+05         pencil  1.186826e+05   0.3627  -6.7006\n",
       "1528   Topic1  1.172538e+05          music  1.172544e+05   0.3627  -6.7127\n",
       "257    Topic1  1.052603e+05      equipment  1.052608e+05   0.3627  -6.8206\n",
       "1002   Topic1  9.303583e+04           stem  9.303639e+04   0.3627  -6.9441\n",
       "369    Topic1  1.080213e+05       computer  1.080220e+05   0.3627  -6.7947\n",
       "331    Topic1  1.078098e+05           food  1.078106e+05   0.3627  -6.7967\n",
       "293    Topic1  9.543977e+04       physical  9.544042e+04   0.3627  -6.9186\n",
       "1859   Topic1  1.018604e+05           team  1.018611e+05   0.3627  -6.8535\n",
       "594    Topic1  8.351898e+04          board  8.351967e+04   0.3627  -7.0520\n",
       "2399   Topic1  8.523794e+04          snack  8.523865e+04   0.3627  -7.0316\n",
       "467    Topic1  7.032928e+04        sensory  7.032988e+04   0.3627  -7.2239\n",
       "312    Topic1  1.523093e+05          basic  1.523106e+05   0.3627  -6.4512\n",
       "1812   Topic1  6.640430e+04         marker  6.640488e+04   0.3627  -7.2813\n",
       "975    Topic1  5.996645e+04         design  5.996700e+04   0.3627  -7.3833\n",
       "528    Topic1  5.995150e+04    engineering  5.995206e+04   0.3627  -7.3835\n",
       "847    Topic1  5.763169e+04            kit  5.763225e+04   0.3627  -7.4230\n",
       "1187   Topic1  5.505954e+04          motor  5.506009e+04   0.3627  -7.4687\n",
       "461    Topic1  6.262721e+04         recess  6.262786e+04   0.3627  -7.3399\n",
       "1857   Topic1  5.525469e+04            lab  5.525529e+04   0.3627  -7.4651\n",
       "0      Topic1  4.322541e+05       activity  4.326211e+05   0.3619  -5.4081\n",
       "620    Topic1  1.342294e+05        concept  1.342422e+05   0.3626  -6.5775\n",
       "345    Topic1  1.612450e+05        problem  1.615939e+05   0.3605  -6.3941\n",
       "434    Topic1  8.033173e+04     creativity  8.033802e+04   0.3626  -7.0909\n",
       "1364   Topic1  7.160080e+04    interactive  7.160256e+04   0.3627  -7.2060\n",
       "1354   Topic1  6.943766e+04          color  6.943886e+04   0.3627  -7.2366\n",
       "656    Topic1  2.013364e+05           tool  2.042765e+05   0.3482  -6.1721\n",
       "807    Topic1  6.267034e+05       material  6.846643e+05   0.2742  -5.0366\n",
       "92     Topic1  6.398211e+05            use  7.051254e+05   0.2655  -5.0159\n",
       "237    Topic1  2.329274e+05          using  2.462303e+05   0.3072  -6.0263\n",
       "433    Topic1  3.539457e+05         create  3.922689e+05   0.2599  -5.6079\n",
       "280    Topic1  1.288023e+06       learning  1.613980e+06   0.1371  -4.3162\n",
       "610    Topic1  6.071381e+05          skill  7.191468e+05   0.1934  -5.0683\n",
       "74     Topic1  1.993745e+06         school  2.680278e+06   0.0668  -3.8793\n",
       "224    Topic1  5.219252e+05        project  6.318401e+05   0.1716  -5.2195\n",
       "99     Topic1  6.674813e+05           work  8.397514e+05   0.1331  -4.9736\n",
       "126    Topic1  2.840426e+05      education  3.221420e+05   0.2368  -5.8279\n",
       "56     Topic1  9.890651e+05           need  1.378001e+06   0.0311  -4.5803\n",
       "47     Topic1  8.954535e+05          learn  1.234947e+06   0.0412  -4.6797\n",
       "35     Topic1  9.822239e+05           help  1.406811e+06   0.0034  -4.5872\n",
       "285    Topic1  5.387349e+05           make  7.105171e+05   0.0859  -5.1878\n",
       "838    Topic1  3.798437e+05     experience  4.698894e+05   0.1500  -5.5373\n",
       "415    Topic1  2.317858e+05           used  2.616535e+05   0.2415  -6.0313\n",
       "96     Topic1  3.899899e+05            way  5.094921e+05   0.0954  -5.5109\n",
       "104    Topic1  4.759903e+05           also  6.606667e+05   0.0348  -5.3117\n",
       "53     Topic1  6.814276e+05           many  1.053996e+06  -0.0735  -4.9529\n",
       "455    Topic1  3.904699e+05    opportunity  5.149750e+05   0.0859  -5.5097\n",
       "8      Topic1  5.743974e+05           come  8.517638e+05  -0.0313  -5.1237\n",
       "13     Topic1  5.212256e+05            day  7.584820e+05  -0.0124  -5.2209\n",
       "182    Topic1  4.733312e+05           able  6.814150e+05  -0.0017  -5.3173\n",
       "101    Topic1  5.584302e+05           year  8.649758e+05  -0.0749  -5.1519\n",
       "110    Topic1  4.609212e+05          child  6.723261e+05  -0.0148  -5.3438\n",
       "100    Topic1  4.087734e+05          would  5.638903e+05   0.0410  -5.4639\n",
       "510    Topic1  4.153003e+05           time  6.291076e+05  -0.0526  -5.4481\n",
       "58     Topic1  4.100082e+05            new  6.913988e+05  -0.1598  -5.4609\n",
       "95     Topic1  4.008748e+05           want  6.948006e+05  -0.1873  -5.4834\n",
       "339    Topic1  3.972235e+05           love  9.059599e+05  -0.4618  -5.4926\n",
       "562    Topic2  1.777422e+06           book  1.777422e+06   1.1901  -3.1668\n",
       "68     Topic2  1.327012e+06        reading  1.327013e+06   1.1901  -3.4590\n",
       "459    Topic2  7.506211e+05           read  7.506218e+05   1.1901  -4.0288\n",
       "673    Topic2  4.120699e+05        library  4.120705e+05   1.1900  -4.6285\n",
       "67     Topic2  2.964720e+05         reader  2.964726e+05   1.1900  -4.9578\n",
       "1381   Topic2  1.741891e+05           text  1.741898e+05   1.1900  -5.4896\n",
       "465    Topic2  1.645745e+05        seating  1.645751e+05   1.1900  -5.5464\n",
       "679    Topic2  9.295107e+04          novel  9.295165e+04   1.1900  -6.1176\n",
       "521    Topic2  1.397966e+05          chair  1.397975e+05   1.1900  -5.7095\n",
       "3011   Topic2  9.953564e+04     literature  9.953643e+04   1.1900  -6.0492\n",
       "2119   Topic2  7.205965e+04     nonfiction  7.206023e+04   1.1900  -6.3722\n",
       "443    Topic2  7.750762e+04       flexible  7.750833e+04   1.1900  -6.2993\n",
       "2113   Topic2  4.977938e+04        fiction  4.977993e+04   1.1900  -6.7421\n",
       "2052   Topic2  5.497228e+04         author  5.497291e+04   1.1900  -6.6429\n",
       "473    Topic2  5.046174e+04          stool  5.046239e+04   1.1900  -6.7285\n",
       "3989   Topic2  5.921812e+04         series  5.921896e+04   1.1900  -6.5685\n",
       "893    Topic2  3.863891e+04          genre  3.863950e+04   1.1900  -6.9955\n",
       "1073   Topic2  8.821310e+04  comprehension  8.821452e+04   1.1900  -6.1700\n",
       "557    Topic2  3.833861e+04         wobble  3.833927e+04   1.1900  -7.0033\n",
       "1047   Topic2  3.069088e+04        leveled  3.069146e+04   1.1900  -7.2258\n",
       "1787   Topic2  2.687249e+04          aloud  2.687311e+04   1.1900  -7.3586\n",
       "2332   Topic2  2.466498e+04        chapter  2.466564e+04   1.1900  -7.4443\n",
       "2198   Topic2  2.210625e+04      biography  2.210688e+04   1.1900  -7.5539\n",
       "2716   Topic2  2.239996e+04      reluctant  2.240065e+04   1.1900  -7.5407\n",
       "511    Topic2  3.939456e+04         wiggle  3.939589e+04   1.1900  -6.9761\n",
       "774    Topic2  2.143374e+04        cushion  2.143455e+04   1.1900  -7.5848\n",
       "7318   Topic2  1.539055e+04          seuss  1.539115e+04   1.1900  -7.9160\n",
       "2211   Topic2  2.247054e+04      selection  2.247143e+04   1.1900  -7.5375\n",
       "2920   Topic2  1.445836e+04          hokki  1.445899e+04   1.1900  -7.9784\n",
       "1106   Topic2  1.322198e+04         alouds  1.322258e+04   1.1900  -8.0678\n",
       "1293   Topic2  5.220423e+04        graphic  5.237584e+04   1.1868  -6.6946\n",
       "1395   Topic2  2.544460e+04       magazine  2.545330e+04   1.1897  -7.4132\n",
       "547    Topic2  1.050430e+05            sit  1.068433e+05   1.1731  -5.9953\n",
       "813    Topic2  7.617359e+04        spanish  8.242182e+04   1.1112  -6.3167\n",
       "1029   Topic2  1.625321e+05          story  1.902780e+05   1.0324  -5.5588\n",
       "563    Topic2  8.761624e+04    comfortable  1.040983e+05   1.0177  -6.1768\n",
       "1236   Topic2  7.362127e+04      character  8.547575e+04   1.0408  -6.3508\n",
       "210    Topic2  1.559622e+05       interest  2.026099e+05   0.9284  -5.6001\n",
       "1912   Topic2  8.872372e+04         option  1.063418e+05   1.0089  -6.1642\n",
       "212    Topic2  3.091628e+05          level  4.482292e+05   0.8186  -4.9158\n",
       "339    Topic2  5.087364e+05           love  9.059599e+05   0.6130  -4.4178\n",
       "19     Topic2  1.793313e+05        english  2.910081e+05   0.7059  -5.4605\n",
       "1147   Topic2  6.863016e+04           desk  8.272866e+04   1.0032  -6.4210\n",
       "207    Topic2  2.925437e+05          grade  6.002069e+05   0.4714  -4.9711\n",
       "50     Topic2  1.175684e+05       literacy  1.763492e+05   0.7846  -5.8827\n",
       "46     Topic2  2.095652e+05       language  4.052788e+05   0.5305  -5.3047\n",
       "95     Topic2  2.939258e+05           want  6.948006e+05   0.3298  -4.9664\n",
       "74     Topic2  6.865335e+05         school  2.680278e+06  -0.1720  -4.1181\n",
       "53     Topic2  3.725680e+05           many  1.053996e+06   0.1501  -4.7293\n",
       "58     Topic2  2.813906e+05            new  6.913988e+05   0.2911  -5.0100\n",
       "35     Topic2  4.245870e+05           help  1.406811e+06  -0.0079  -4.5986\n",
       "101    Topic2  3.065455e+05           year  8.649758e+05   0.1527  -4.9244\n",
       "56     Topic2  3.889362e+05           need  1.378001e+06  -0.0749  -4.6863\n",
       "47     Topic2  3.394934e+05          learn  1.234947e+06  -0.1013  -4.8223\n",
       "8      Topic2  2.773664e+05           come  8.517638e+05   0.0681  -5.0244\n",
       "38     Topic2  1.985092e+05           home  4.821393e+05   0.3027  -5.3589\n",
       "13     Topic2  2.372564e+05            day  7.584820e+05   0.0279  -5.1806\n",
       "510    Topic2  2.138073e+05           time  6.291076e+05   0.1108  -5.2846\n",
       "280    Topic2  3.259579e+05       learning  1.613980e+06  -0.4096  -4.8630\n",
       "110    Topic2  2.114049e+05          child  6.723261e+05   0.0331  -5.2959\n",
       "182    Topic2  2.080837e+05           able  6.814150e+05   0.0038  -5.3118\n",
       "104    Topic2  1.846764e+05           also  6.606667e+05  -0.0846  -5.4311\n",
       "61     Topic2  1.763880e+05            one  5.247701e+05   0.0998  -5.4770\n",
       "285    Topic2  1.717822e+05           make  7.105171e+05  -0.2297  -5.5035\n",
       "99     Topic2  1.722701e+05           work  8.397514e+05  -0.3940  -5.5007, token_table=      Topic          Freq           Term\n",
       "term                                    \n",
       "182       1  6.946295e-01           able\n",
       "182       2  3.053705e-01           able\n",
       "0         1  9.991515e-01       activity\n",
       "0         2  8.483174e-04       activity\n",
       "1787      1  3.721192e-05          aloud\n",
       "1787      2  9.999587e-01          aloud\n",
       "1106      1  7.562818e-05         alouds\n",
       "1106      2  9.999558e-01         alouds\n",
       "104       1  7.204692e-01           also\n",
       "104       2  2.795298e-01           also\n",
       "1403      1  9.999991e-01            art\n",
       "1403      2  2.641608e-06            art\n",
       "2052      1  1.819078e-05         author\n",
       "2052      2  9.999835e-01         author\n",
       "312       1  9.999894e-01          basic\n",
       "312       2  6.565531e-06          basic\n",
       "2198      1  4.523479e-05      biography\n",
       "2198      2  9.999602e-01      biography\n",
       "594       1  9.999920e-01          board\n",
       "594       2  1.197323e-05          board\n",
       "562       1  5.626125e-07           book\n",
       "562       2  9.999998e-01           book\n",
       "521       1  7.153203e-06          chair\n",
       "521       2  9.999963e-01          chair\n",
       "2332      1  4.054223e-05        chapter\n",
       "2332      2  9.999740e-01        chapter\n",
       "1236      1  1.386826e-01      character\n",
       "1236      2  8.613086e-01      character\n",
       "110       1  6.855617e-01          child\n",
       "110       2  3.144382e-01          child\n",
       "1354      1  9.999876e-01          color\n",
       "1354      2  1.440116e-05          color\n",
       "8         1  6.743618e-01           come\n",
       "8         2  3.256372e-01           come\n",
       "563       1  1.583312e-01    comfortable\n",
       "563       2  8.416662e-01    comfortable\n",
       "1073      1  1.133600e-05  comprehension\n",
       "1073      2  9.999828e-01  comprehension\n",
       "369       1  9.999906e-01       computer\n",
       "369       2  9.257372e-06       computer\n",
       "620       1  9.999013e-01        concept\n",
       "620       2  9.683985e-05        concept\n",
       "433       1  9.023045e-01         create\n",
       "433       2  9.769574e-02         create\n",
       "434       1  9.999251e-01     creativity\n",
       "434       2  7.468445e-05     creativity\n",
       "774       1  4.665365e-05        cushion\n",
       "774       2  9.999743e-01        cushion\n",
       "13        1  6.871963e-01            day\n",
       "13        2  3.128037e-01            day\n",
       "975       1  9.999834e-01         design\n",
       "975       2  1.667584e-05         design\n",
       "1147      1  1.704246e-01           desk\n",
       "1147      2  8.295795e-01           desk\n",
       "126       1  8.817323e-01      education\n",
       "126       2  1.182677e-01      education\n",
       "528       1  9.999990e-01    engineering\n",
       "528       2  1.667999e-05    engineering\n",
       "19        1  3.837591e-01        english\n",
       "19        2  6.162406e-01        english\n",
       "257       1  9.999923e-01      equipment\n",
       "257       2  9.500211e-06      equipment\n",
       "838       1  8.083690e-01     experience\n",
       "838       2  1.916323e-01     experience\n",
       "2113      1  2.008842e-05        fiction\n",
       "2113      2  9.999812e-01        fiction\n",
       "443       1  1.290184e-05       flexible\n",
       "443       2  9.999958e-01       flexible\n",
       "331       1  9.999949e-01           food\n",
       "331       2  9.275530e-06           food\n",
       "638       1  9.999966e-01           game\n",
       "638       2  3.814845e-06           game\n",
       "893       1  2.588025e-05          genre\n",
       "893       2  9.999869e-01          genre\n",
       "207       1  5.125949e-01          grade\n",
       "207       2  4.874053e-01          grade\n",
       "1293      1  3.283957e-03        graphic\n",
       "1293      2  9.967192e-01        graphic\n",
       "984       1  9.999985e-01        handson\n",
       "984       2  7.039615e-06        handson\n",
       "334       1  9.999943e-01        healthy\n",
       "334       2  7.655107e-06        healthy\n",
       "35        1  6.981919e-01           help\n",
       "35        2  3.018081e-01           help\n",
       "2920      1  6.916112e-05          hokki\n",
       "2920      2  9.999315e-01          hokki\n",
       "38        1  5.882740e-01           home\n",
       "38        2  4.117254e-01           home\n",
       "1364      1  9.999782e-01    interactive\n",
       "1364      2  2.793196e-05    interactive\n",
       "210       1  2.302355e-01       interest\n",
       "210       2  7.697648e-01       interest\n",
       "940       1  9.999982e-01           item\n",
       "940       2  5.726219e-06           item\n",
       "847       1  9.999956e-01            kit\n",
       "847       2  1.735140e-05            kit\n",
       "1857      1  9.999948e-01            lab\n",
       "1857      2  1.809782e-05            lab\n",
       "46        1  4.829120e-01       language\n",
       "46        2  5.170885e-01       language\n",
       "47        1  7.250952e-01          learn\n",
       "47        2  2.749049e-01          learn\n",
       "280       1  7.980412e-01       learning\n",
       "280       2  2.019591e-01       learning\n",
       "212       1  3.102564e-01          level\n",
       "212       2  6.897430e-01          level\n",
       "1047      1  3.258236e-05        leveled\n",
       "1047      2  9.999851e-01        leveled\n",
       "673       1  2.426769e-06        library\n",
       "673       2  9.999987e-01        library\n",
       "50        1  3.333216e-01       literacy\n",
       "50        2  6.666773e-01       literacy\n",
       "3011      1  1.004657e-05     literature\n",
       "3011      2  9.999957e-01     literature\n",
       "339       1  4.384565e-01           love\n",
       "339       2  5.615436e-01           love\n",
       "1395      1  3.535887e-04       magazine\n",
       "1395      2  9.996737e-01       magazine\n",
       "285       1  7.582294e-01           make\n",
       "285       2  2.417704e-01           make\n",
       "53        1  6.465189e-01           many\n",
       "53        2  3.534816e-01           many\n",
       "1812      1  9.999867e-01         marker\n",
       "1812      2  1.505913e-05         marker\n",
       "807       1  9.153435e-01       material\n",
       "807       2  8.465608e-02       material\n",
       "385       1  9.999987e-01           math\n",
       "385       2  2.325151e-06           math\n",
       "1187      1  9.999985e-01          motor\n",
       "1187      2  1.816198e-05          motor\n",
       "1528      1  9.999965e-01          music\n",
       "1528      2  8.528464e-06          music\n",
       "56        1  7.177534e-01           need\n",
       "56        2  2.822465e-01           need\n",
       "58        1  5.930123e-01            new\n",
       "58        2  4.069880e-01            new\n",
       "2119      1  1.387728e-05     nonfiction\n",
       "2119      2  9.999968e-01     nonfiction\n",
       "679       1  1.075828e-05          novel\n",
       "679       2  9.999930e-01          novel\n",
       "61        1  6.638755e-01            one\n",
       "61        2  3.361243e-01            one\n",
       "455       1  7.582310e-01    opportunity\n",
       "455       2  2.417690e-01    opportunity\n",
       "1912      1  1.656733e-01         option\n",
       "1912      2  8.343285e-01         option\n",
       "1219      1  9.999985e-01          paper\n",
       "1219      2  7.035702e-06          paper\n",
       "727       1  9.999954e-01         pencil\n",
       "727       2  8.425838e-06         pencil\n",
       "293       1  9.999956e-01       physical\n",
       "293       2  1.047774e-05       physical\n",
       "456       1  9.999974e-01           play\n",
       "456       2  3.927457e-06           play\n",
       "345       1  9.978408e-01        problem\n",
       "345       2  2.159735e-03        problem\n",
       "224       1  8.260397e-01        project\n",
       "224       2  1.739601e-01        project\n",
       "459       1  1.332229e-06           read\n",
       "459       2  9.999990e-01           read\n",
       "67        1  3.372993e-06         reader\n",
       "67        2  9.999980e-01         reader\n",
       "68        1  7.535724e-07        reading\n",
       "68        2  9.999995e-01        reading\n",
       "461       1  9.999864e-01         recess\n",
       "461       2  1.596734e-05         recess\n",
       "2716      1  4.464157e-05      reluctant\n",
       "2716      2  9.999712e-01      reluctant\n",
       "74        1  7.438574e-01         school\n",
       "74        2  2.561428e-01         school\n",
       "228       1  9.999983e-01        science\n",
       "228       2  2.902070e-06        science\n",
       "465       1  6.076254e-06        seating\n",
       "465       2  9.999934e-01        seating\n",
       "2211      1  4.450095e-05      selection\n",
       "2211      2  9.999810e-01      selection\n",
       "467       1  9.999875e-01        sensory\n",
       "467       2  1.421871e-05        sensory\n",
       "3989      1  1.688648e-05         series\n",
       "3989      2  9.999838e-01         series\n",
       "7318      1  6.497241e-05          seuss\n",
       "7318      2  9.999903e-01          seuss\n",
       "547       1  1.684711e-02            sit\n",
       "547       2  9.831504e-01            sit\n",
       "610       1  8.442477e-01          skill\n",
       "610       2  1.557526e-01          skill\n",
       "2399      1  9.999924e-01          snack\n",
       "2399      2  1.173177e-05          snack\n",
       "813       1  7.580517e-02        spanish\n",
       "813       2  9.241970e-01        spanish\n",
       "1002      1  9.999958e-01           stem\n",
       "1002      2  1.074848e-05           stem\n",
       "473       1  1.981674e-05          stool\n",
       "473       2  9.999922e-01          stool\n",
       "1029      1  1.458182e-01          story\n",
       "1029      2  8.541818e-01          story\n",
       "730       1  9.999989e-01         supply\n",
       "730       2  2.389027e-06         supply\n",
       "1859      1  9.999889e-01           team\n",
       "1859      2  9.817287e-06           team\n",
       "233       1  9.999992e-01     technology\n",
       "233       2  3.162983e-06     technology\n",
       "1381      1  5.740864e-06           text\n",
       "1381      2  9.999954e-01           text\n",
       "510       1  6.601414e-01           time\n",
       "510       2  3.398576e-01           time\n",
       "656       1  9.856053e-01           tool\n",
       "656       2  1.439226e-02           tool\n",
       "92        1  9.073861e-01            use\n",
       "92        2  9.261332e-02            use\n",
       "415       1  8.858510e-01           used\n",
       "415       2  1.141510e-01           used\n",
       "237       1  9.459723e-01          using\n",
       "237       2  5.402666e-02          using\n",
       "95        1  5.769641e-01           want\n",
       "95        2  4.230365e-01           want\n",
       "96        1  7.654485e-01            way\n",
       "96        2  2.345512e-01            way\n",
       "511       1  2.538336e-05         wiggle\n",
       "511       2  9.999773e-01         wiggle\n",
       "557       1  2.608292e-05         wobble\n",
       "557       2  9.999930e-01         wobble\n",
       "99        1  7.948554e-01           work\n",
       "99        2  2.051440e-01           work\n",
       "100       1  7.249158e-01          would\n",
       "100       2  2.750836e-01          would\n",
       "101       1  6.456019e-01           year\n",
       "101       2  3.543984e-01           year, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize topics-keywords\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5:  Make an LDA topic model for the DESCRIPTIONS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same K (and any other hyperparameters from Part 4), recompute a model for Descriptions. Compare the two sets of results. Do they vary? How? Why? Explain what you find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(70678 unique tokens: ['apple', 'blue', 'gb', 'generation', 'ipod']...)\n",
      "[(0,\n",
      "  '0.022*\"pack\" + 0.018*\"black\" + 0.017*\"gb\" + 0.015*\"color\" + 0.011*\"inch\" + '\n",
      "  '0.011*\"ipad\" + 0.009*\"kid\" + 0.009*\"mini\" + 0.008*\"blue\" + 0.008*\"paper\"'),\n",
      " (1,\n",
      "  '0.036*\"set\" + 0.018*\"book\" + 0.009*\"ball\" + 0.008*\"kit\" + 0.007*\"game\" + '\n",
      "  '0.006*\"kid\" + 0.006*\"level\" + 0.005*\"gr\" + 0.005*\"learning\" + '\n",
      "  '0.005*\"balance\"')]\n",
      "Best K:  2     Best coherence Score:  -5.685597133881545\n"
     ]
    }
   ],
   "source": [
    "data_description = data['description'].tolist()\n",
    "\n",
    "id2word = corpora.Dictionary(data_description)\n",
    "texts = data_description\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(id2word)\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus, best_K, id2word)\n",
    "cm = CoherenceModel(model=lda_model, corpus=corpus, coherence='u_mass')\n",
    "coherence = cm.get_coherence()  # get coherence value\n",
    "    \n",
    "pprint(lda_model.print_topics())\n",
    "print('Best K: ', best_K, '    Best coherence Score: ', coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "First of all, the coherence score of \"essays\" is much better then the one of \"Description\" for a K = 2 topics.\n",
    "\n",
    "When we look at the topics of \"essays\" and if we take aside the terms refering to school which \n",
    "were not filtered by the stopword function, we see that overall the topics refer to \"need\" or \"love\" showing \n",
    "that maybe the essays can be divided in two approaches which involve saying how much funding \n",
    "is needed or how much the students would love the project.\n",
    "\n",
    "When we look at the topics of \"description\", we can see that the first topic may refer to the aspect of resource requested\n",
    "the second does not really make sense. This explains the variation in coherence score.\n",
    "Probably the \"description\" requires much more topics in order to have meaningful information.\n",
    "\n",
    "Also, we have to take into account the fact that when the two datasets were merged, some essays were replicated and\n",
    "this might also have an impact on the coherence of the topics model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
